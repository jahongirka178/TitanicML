import streamlit as st
import pandas as pd

from sklearn.model_selection import train_test_split
from sklearn.metrics import roc_curve, auc, accuracy_score, f1_score
from sklearn.tree import DecisionTreeClassifier
from sklearn.neighbors import KNeighborsClassifier
from sklearn.linear_model import LogisticRegression
from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, StackingClassifier
from sklearn.pipeline import make_pipeline
from sklearn.preprocessing import StandardScaler
import category_encoders as ce
import plotly.express as px

pd.set_option("display.float_format", "{:.2f}".format)


def get_metrics(y, y_pred, y_proba):
    fpr, tpr, thresholds = roc_curve(y, y_proba)
    return auc(fpr, tpr), accuracy_score(y, y_pred), f1_score(y, y_pred)


def show_roc(y, y_pred, y_proba, title):
    fpr, tpr, _ = roc_curve(y, y_proba)
    auc_score = auc(fpr, tpr)
    accuracy = accuracy_score(y, y_pred)
    f1 = f1_score(y, y_pred)

    df_roc = pd.DataFrame({
        "False Positive Rate": fpr,
        "True Positive Rate": tpr
    })

    fig = px.line(
        df_roc,
        x="False Positive Rate",
        y="True Positive Rate",
        title=f"{title}. AUC={auc_score:.4f}. Accuracy={accuracy * 100:.2f}%. F1={f1:.4f}.",
        markers=True
    )
    # –î–æ–±–∞–≤–ª—è–µ–º –¥–∏–∞–≥–æ–Ω–∞–ª—å —Å–ª—É—á–∞–π–Ω–æ–≥–æ –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ç–æ—Ä–∞
    fig.add_shape(
        type="line",
        x0=0, y0=0, x1=1, y1=1,
        line=dict(dash="dash", color="grey")
    )
    fig.update_layout(
        xaxis_title="False Positive Rate",
        yaxis_title="True Positive Rate",
        template="plotly_white"
    )
    st.plotly_chart(fig, use_container_width=True)


def analyze_model(X_train, X_test, y_train, y_test, model, model_name):
    model.fit(X_train, y_train)

    y_pred_test = model.predict(X_test)
    y_proba_test = model.predict_proba(X_test)[:, 1]

    y_pred_train = model.predict(X_train)
    y_proba_train = model.predict_proba(X_train)[:, 1]

    auc_score_test, accuracy_test, f1_test = get_metrics(y_test, y_pred_test, y_proba_test)
    auc_score_train, accuracy_train, f1_train = get_metrics(y_train, y_pred_train, y_proba_train)

    show_roc(y_test, y_pred_test, y_proba_test, f'{model_name}')

    return {
        'model': model_name,
        'auc_test': auc_score_test,
        'auc_train': auc_score_train,
        'accuracy_test': accuracy_test,
        'accuracy_train': accuracy_train,
        'f1_test': f1_test,
        'f1_train': f1_train,
    }


def get_fare_category(fare: float) -> str:
    """
    –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç –∫–∞—Ç–µ–≥–æ—Ä–∏—é —Ç–∞—Ä–∏—Ñ–∞ –ø–æ –∑–Ω–∞—á–µ–Ω–∏—é fare,
    –∏—Å–ø–æ–ª—å–∑—É—è —Ç–µ –∂–µ –∫–≤–∞–Ω—Ç–∏–ª—å–Ω—ã–µ –≥—Ä–∞–Ω–∏—Ü—ã, —á—Ç–æ –∏ pd.qcut.

    Parameters:
        fare (float): –ó–Ω–∞—á–µ–Ω–∏–µ —Ç–∞—Ä–∏—Ñ–∞

    Returns:
        str: –û–¥–Ω–∞ –∏–∑ –∫–∞—Ç–µ–≥–æ—Ä–∏–π ['Low', 'Medium', 'High', 'VeryHigh']
    """
    quantiles = [0, 0.3, 0.5, 0.85, 1.0]
    labels = ['Low', 'Medium', 'High', 'VeryHigh']
    bins = df['Fare'].quantile(quantiles).values

    # –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º –≤—Ä—É—á–Ω—É—é —á–µ—Ä–µ–∑ pd.cut (–æ–¥–∏–Ω–æ—á–Ω—ã–π —ç–ª–µ–º–µ–Ω—Ç)
    category = pd.cut([fare], bins=bins, labels=labels, include_lowest=True)[0]

    return str(category)


def get_age_group(age: float) -> str:
    """
    –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç –≤–æ–∑—Ä–∞—Å—Ç–Ω—É—é –∫–∞—Ç–µ–≥–æ—Ä–∏—é –Ω–∞ –æ—Å–Ω–æ–≤–µ –∑–Ω–∞—á–µ–Ω–∏—è –≤–æ–∑—Ä–∞—Å—Ç–∞.

    Parameters:
        age (float): –í–æ–∑—Ä–∞—Å—Ç

    Returns:
        str: –û–¥–Ω–∞ –∏–∑ –∫–∞—Ç–µ–≥–æ—Ä–∏–π ['Child', 'Teen', 'YoungAdult', 'Adult', 'Senior']
    """
    if age <= 12:
        return 'Child'
    elif age <= 19:
        return 'Teen'
    elif age <= 35:
        return 'YoungAdult'
    elif age <= 59:
        return 'Adult'
    else:
        return 'Senior'


# –ù–∞—Å—Ç—Ä–æ–π–∫–∞ —Å—Ç—Ä–∞–Ω–∏—Ü—ã
st.set_page_config(page_title='üö¢ Titanic Classifier', layout='wide')
st.title("üö¢ –î–∞—Ç–∞—Å–µ—Ç Titanic - –û–±—É—á–µ–Ω–∏–µ –∏ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ")
st.header('–†–∞–±–æ—Ç–∞ —Å –¥–∞—Ç–∞—Å–µ—Ç–æ–º Titanic')

# –ó–∞–≥—Ä—É–∑–∫–∞ –¥–∞–Ω–Ω—ã—Ö
url = "https://raw.githubusercontent.com/jahongirka178/TitanicML/refs/heads/master/data/titanic_for_hw.csv"
df = pd.read_csv(url)

# –¢–∞–±–ª–∏—Ü–∞
st.subheader('–î–∞–Ω–Ω—ã–µ')
st.dataframe(df.round(2), use_container_width=True)

# –í–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è
st.write('## –í–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è')

col1, col2 = st.columns(2)

with col1:
    fig1 = px.histogram(df, x='Survived', color='Sex', barmode='group',
                        title='–í—ã–∂–∏–≤—à–∏–µ –ø–æ –ø–æ–ª—É')
    st.plotly_chart(fig1, use_container_width=True)

with col2:
    fig2 = px.histogram(df, x='Pclass', color='Survived', barmode='group',
                        title='–†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –∫–ª–∞—Å—Å–æ–≤ –ø–æ –≤—ã–∂–∏–≤—à–∏–º')
    st.plotly_chart(fig2, use_container_width=True)

col3, col4 = st.columns(2)

with col3:
    fig3 = px.histogram(df, x='Fare', nbins=50, color='Survived',
                        title='–†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ —Å—Ç–æ–∏–º–æ—Å—Ç–∏ –±–∏–ª–µ—Ç–∞ –ø–æ –≤—ã–∂–∏–≤—à–∏–º', opacity=0.6)
    st.plotly_chart(fig3, use_container_width=True)

with col4:
    fig4 = px.histogram(df, x='Age', nbins=40, color='Survived',
                        title='–†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –≤–æ–∑—Ä–∞—Å—Ç–∞ –ø–æ –≤—ã–∂–∏–≤—à–∏–º', opacity=0.6)
    st.plotly_chart(fig4, use_container_width=True)

# –ú–æ–¥–µ–ª–∏—Ä–æ–≤–∞–Ω–∏–µ
X = df.drop(columns=['Survived', 'Name', 'Cabin'])
y = df['Survived']

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42, stratify=y)

encoder = ce.TargetEncoder(cols=['Sex', 'Embarked', 'Title', 'FareCategory', 'AgeGroup'])
X_train_encoded = encoder.fit_transform(X_train, y_train)
X_test_encoded = encoder.transform(X_test)

models = {
    'Decision Tree': DecisionTreeClassifier(random_state=42),
    'KNN': make_pipeline(StandardScaler(), KNeighborsClassifier(9)),
    'Logistic Regression': make_pipeline(StandardScaler(),
                                         LogisticRegression(C=0.01, max_iter=1000, penalty='l1', solver='liblinear')),
    'Random Forest': RandomForestClassifier(
        n_estimators=100,
        max_depth=8,
        min_samples_split=5,
        min_samples_leaf=2,
        max_features='sqrt',
        criterion='entropy',
        random_state=42),
    'Gradient Boosting': GradientBoostingClassifier(
        n_estimators=100,
        learning_rate=0.1,
        max_depth=10,
        random_state=42
    )

}

results = []
for name, model in models.items():
    model.fit(X_train_encoded, y_train)
    acc_train = accuracy_score(y_train, model.predict(X_train_encoded))
    acc_test = accuracy_score(y_test, model.predict(X_test_encoded))
    results.append({
        'Model': name,
        'Test Accuracy': acc_test,
        'Train Accuracy': acc_train
    })

st.write('## –°—Ä–∞–≤–Ω–µ–Ω–∏–µ –º–æ–¥–µ–ª–µ–π –ø–æ —Ç–æ—á–Ω–æ—Å—Ç–∏')
st.table(pd.DataFrame(results).round(2))

# Sidebar –¥–ª—è –≤–≤–æ–¥–∞ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è
st.sidebar.header('–ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ –ø–æ –ø–∞—Ä–∞–º–µ—Ç—Ä–∞–º')

sex_input = st.sidebar.selectbox('–ü–æ–ª', df['Sex'].unique())
embarked_input = st.sidebar.selectbox('–ü–æ—Ä—Ç –ø–æ—Å–∞–¥–∫–∏', df['Embarked'].unique())
title_input = st.sidebar.selectbox('–û–±—Ä–∞—â–µ–Ω–∏–µ', df['Title'].unique())
pclass = st.sidebar.selectbox('–ö–ª–∞—Å—Å –±–∏–ª–µ—Ç–∞', sorted(df['Pclass'].unique()))

age = st.sidebar.slider('–í–æ–∑—Ä–∞—Å—Ç',
                        float(df['Age'].min()),
                        float(df['Age'].max()),
                        float((df['Age'].min() + df['Age'].max()) / 2)
                        )

fare = st.sidebar.slider(
    '–°—Ç–æ–∏–º–æ—Å—Ç—å –±–∏–ª–µ—Ç–∞',
    float(df['Fare'].min()),
    float(df['Fare'].max()),
    float((df['Fare'].min() + df['Fare'].max()) / 2)
)

family_size = st.sidebar.slider(
    '–†–∞–∑–º–µ—Ä —Å–µ–º—å–∏',
    0,
    int(df['family_size'].max()),
    int(df['family_size'].max() / 2)
)
is_alone = int(family_size == 0)

user_input = pd.DataFrame([{
    'Pclass': pclass,
    'Sex': sex_input,
    'Age': age,
    'Fare': fare,
    'Embarked': embarked_input,
    'Title': title_input,
    'FareCategory': get_fare_category(fare),
    'family_size': family_size,
    'is_alone': is_alone,
    'AgeGroup': get_age_group(age)
}])

df = df.round(2)

user_encoded = encoder.transform(user_input)

for col in ['Pclass', 'Age', 'Fare', 'family_size', 'is_alone']:
    user_encoded[col] = user_input[col].values

user_encoded = user_encoded[X_train_encoded.columns]

# st.dataframe(user_input, use_container_width=True)

st.sidebar.subheader("üìà –†–µ–∑—É–ª—å—Ç–∞—Ç—ã –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è")

for name, model in models.items():
    y_pred = model.predict(user_encoded)[0]
    y_proba = model.predict_proba(user_encoded)[0]
    st.sidebar.markdown(f"**{name}: {'–í—ã–∂–∏–ª' if y_pred == 1 else '–ù–µ –≤—ã–∂–∏–ª'}**")
    proba_df = pd.DataFrame({'–ö–ª–∞—Å—Å': ['–ù–µ –≤—ã–∂–∏–ª', '–í—ã–∂–∏–ª'], '–í–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç—å': y_proba})
    st.sidebar.dataframe(proba_df.set_index("–ö–ª–∞—Å—Å"), use_container_width=True)

# ROC-AUC —Å –≤—ã–±–æ—Ä–æ–º –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ç–æ—Ä–∞
st.write("## –ê–Ω–∞–ª–∏–∑ –º–æ–¥–µ–ª–µ–π")
model_choice = st.selectbox(
    "–í—ã–±–µ—Ä–∏—Ç–µ –º–æ–¥–µ–ª—å:",
    list(models.keys()),
    index=0
)

model = models[model_choice]

test_size = st.slider(
    "–î–æ–ª—è —Ç–µ—Å—Ç–æ–≤–æ–π –≤—ã–±–æ—Ä–∫–∏",
    min_value=0.1,
    max_value=0.5,
    value=0.3,
    step=0.05,
    help="–°–ª–∏—à–∫–æ–º –º–∞–ª—ã–π –∏–ª–∏ —Å–ª–∏—à–∫–æ–º –±–æ–ª—å—à–æ–π —Ä–∞–∑–º–µ—Ä –º–æ–∂–µ—Ç –ø–æ–≤–ª–∏—è—Ç—å –Ω–∞ —Å—Ç–∞–±–∏–ª—å–Ω–æ—Å—Ç—å —Å—Ç—Ä–∞—Ç–∏—Ñ–∏–∫–∞—Ü–∏–∏."
)

encoder_options = {
    "OneHotEncoder": ce.OneHotEncoder,
    "OrdinalEncoder": ce.OrdinalEncoder,
    "TargetEncoder": ce.TargetEncoder,
    "CatBoostEncoder": ce.CatBoostEncoder,
    "LeaveOneOutEncoder": ce.LeaveOneOutEncoder,
    "BinaryEncoder": ce.BinaryEncoder,
}

encoder_name = st.selectbox("–í—ã–±–µ—Ä–∏—Ç–µ encoder", list(encoder_options.keys()), index=2)  # –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é TargetEncoder
EncoderClass = encoder_options[encoder_name]

encoder = EncoderClass(cols=['Sex', 'Embarked', 'Title', 'FareCategory', 'AgeGroup'])

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size, random_state=42, stratify=y)

X_train_encoded = encoder.fit_transform(X_train, y_train)
X_test_encoded = encoder.transform(X_test)

result = pd.DataFrame([analyze_model(X_train_encoded, X_test_encoded, y_train, y_test, model, model_choice)])
st.subheader("–†–µ–∑—É–ª—å—Ç–∞—Ç—ã –∞–Ω–∞–ª–∏–∑–∞")
st.dataframe(result)

st.write("## Stacking")

encoder_name = st.selectbox("–í—ã–±–µ—Ä–∏—Ç–µ encoder –¥–ª—è Stacking", list(encoder_options.keys()),
                            index=2)  # –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é TargetEncoder
EncoderClass = encoder_options[encoder_name]

encoder = EncoderClass(cols=['Sex', 'Embarked', 'Title', 'FareCategory', 'AgeGroup'])

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42, stratify=y)
X_train_encoded = encoder.fit_transform(X_train, y_train)
X_test_encoded = encoder.transform(X_test)

'''
# 1. –≤—ã–±–æ—Ä —Ç—Ä—ë—Ö –±–∞–∑–æ–≤—ã—Ö –º–æ–¥–µ–ª–µ–π
stacking_models = st.multiselect(
    "–í—ã–±–µ—Ä–∏—Ç–µ —Ä–æ–≤–Ω–æ 3 –º–æ–¥–µ–ª–∏ –¥–ª—è —Å—Ç–µ–∫–∏–Ω–≥–∞ (–±–∞–∑–æ–≤—ã–µ –º–æ–¥–µ–ª–∏):",
    options=list(models.keys()),
    default=list(models.keys())[:3],  # –ª—é–±—ã–µ 3 –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é
    help="–ë–∞–∑–æ–≤—ã–µ (–ø–µ—Ä–≤–æ–≥–æ —É—Ä–æ–≤–Ω—è) –º–æ–¥–µ–ª–∏"
)

# 2. –≤—ã–±–æ—Ä —Ñ–∏–Ω–∞–ª—å–Ω–æ–π (–º–µ—Ç–∞)-–º–æ–¥–µ–ª–∏
final_model_name = st.selectbox(
    "–í—ã–±–µ—Ä–∏—Ç–µ —Ñ–∏–Ω–∞–ª—å–Ω—É—é –º–æ–¥–µ–ª—å (–º–µ—Ç–∞-–º–æ–¥–µ–ª—å):",
    options=list(models.keys()),
    index=3,
    help="–≠—Ç–∞ –º–æ–¥–µ–ª—å –æ–±—É—á–∞–µ—Ç—Å—è –Ω–∞ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è—Ö –±–∞–∑–æ–≤—ã—Ö –º–æ–¥–µ–ª–µ–π"
)

'''

stacking_models = ['Decision Tree', 'Random Forest', 'Logistic Regression']
final_model_name = 'KNN'

# 3. –∫–Ω–æ–ø–∫–∞ –∑–∞–ø—É—Å–∫–∞
launch_stacking = st.button("üöÄ –ó–∞–ø—É—Å—Ç–∏—Ç—å Stacking")

# 4. –ª–æ–≥–∏–∫–∞ –∑–∞–ø—É—Å–∫–∞
if launch_stacking:
    estimators = [(name, models[name]) for name in stacking_models]
    final_model = models[final_model_name]

    stacking_clf = StackingClassifier(
        estimators=estimators,
        final_estimator=final_model,
        passthrough=True,  # –¥–æ–±–∞–≤–ª—è—Ç—å –ª–∏ –∏—Å—Ö–æ–¥–Ω—ã–µ –ø—Ä–∏–∑–Ω–∞–∫–∏ –≤–æ –≤—Ç–æ—Ä–æ–π —É—Ä–æ–≤–µ–Ω—å
        cv=5,
        n_jobs=-1
    )

    stacking_result = analyze_model(
        X_train_encoded, X_test_encoded,
        y_train, y_test,
        stacking_clf, "Stacking"
    )

    st.subheader("–†–µ–∑—É–ª—å—Ç–∞—Ç—ã —Å—Ç–µ–∫–∏–Ω–≥–∞")
    st.dataframe(pd.DataFrame([stacking_result]).round(3))
